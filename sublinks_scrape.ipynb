{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b8630b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html2text\n",
      "  Using cached html2text-2024.2.26-py3-none-any.whl\n",
      "Installing collected packages: html2text\n",
      "Successfully installed html2text-2024.2.26\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfd384f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping successful!\n"
     ]
    }
   ],
   "source": [
    "import html2text\n",
    "import requests\n",
    "\n",
    "def do_webscraping(link):\n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "        response.raise_for_status()  # Raise an exception for non-2xx status codes\n",
    "\n",
    "        html_content = response.text\n",
    "        clean_content = html2text.html2text(html_content)\n",
    "\n",
    "        # Write content to a text file\n",
    "        with open('output.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(clean_content)\n",
    "\n",
    "\n",
    "        return clean_content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    result = do_webscraping('https://pratham.org/')\n",
    "    if result:\n",
    "        print(\"Scraping successful!\")\n",
    "    else:\n",
    "        print(\"Scraping failed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf7da4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main page scraped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee6e5c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Paragraph\n",
      "0                                     Skip to content\n",
      "1   __[![Pratham](https://pratham.org/wp-content/u...\n",
      "2     * [About Us](https://pratham.org/about/)\\n  ...\n",
      "3   [Donate](https://www.pratham.org/get-involved/...\n",
      "4   ![](https://pratham.org/wp-content/uploads/202...\n",
      "5                                         Early Years\n",
      "6   Focusing on the holistic development of childr...\n",
      "7   [ Read More ](https://pratham.org/slider/ece-s...\n",
      "8   ![](https://pratham.org/wp-content/uploads/202...\n",
      "9                                       Second Chance\n",
      "10  Supporting girls and women with completing the...\n",
      "11  [ Read More ](https://pratham.org/slider/secon...\n",
      "12  ![](https://pratham.org/wp-content/uploads/202...\n",
      "13                                Vocational Training\n",
      "14  Equipping youth with employable skills & acces...\n",
      "15  [ Read More ](https://pratham.org/slider/skill...\n",
      "16  ![](https://pratham.org/wp-content/uploads/202...\n",
      "17                           ASER 2023: Beyond Basics\n",
      "18  Provides evidence on youth (14â€“18 year-olds) e...\n",
      "19  [ Read More ](https://pratham.org/slider/aser-...\n",
      "20                                             # Home\n",
      "21                                      ###  About Us\n",
      "22  Pratham is an innovative learning organization...\n",
      "23  As one of the largest non-governmental organiz...\n",
      "24                                      ###  Programs\n",
      "25  [ ![Education](https://pratham.org/wp-content/...\n",
      "26  ### [Education](https://pratham.org/programs/e...\n",
      "27                                      ### Education\n",
      "28  Across the spectrum from Early Childhood Educa...\n",
      "29  [Learn More](https://pratham.org/programs/educ...\n",
      "30  [ ![Vocational Training](https://pratham.org/w...\n",
      "31  ### [Vocational Training](https://pratham.org/...\n",
      "32  [ ![ASER](https://pratham.org/wp-content/uploa...\n",
      "33  ### [ASER](https://pratham.org/programs/educat...\n",
      "34  [ ![PCVC](https://pratham.org/wp-content/uploa...\n",
      "35  ### [PCVC](https://pratham.org/programs/pratha...\n",
      "36                      ###  Progress-O-Meter 2022-23\n",
      "37                                      Activities in\n",
      "38  ![](https://pratham.org/wp-content/uploads/202...\n",
      "39                         States & Union Territories\n",
      "40                         Government partnerships in\n",
      "41  ![](https://pratham.org/wp-content/uploads/202...\n",
      "42                         States & Union Territories\n",
      "43                                 Activities engaged\n",
      "44  ![](https://pratham.org/wp-content/uploads/202...\n",
      "45                               Parents & Volunteers\n",
      "46                                   Programs reached\n",
      "47  ![](https://pratham.org/wp-content/uploads/202...\n",
      "48                                   Children & Youth\n",
      "49                                  ###  Get Involved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to read the text file into paragraphs\n",
    "def read_paragraphs(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        paragraphs = file.read().split('\\n\\n')  # Split by double newline to separate paragraphs\n",
    "    return pd.DataFrame(paragraphs, columns=['Paragraph'])\n",
    "\n",
    "# Read the file\n",
    "df = read_paragraphs('output.txt')\n",
    "\n",
    "# Display the dataframe\n",
    "print(df.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51584702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# many links in file . Scrape those links as well with ignoring files with other. extension than text as that will eresulkt in gibberish content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b7328b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://pratham.org/camal-ka-camp-2023/\n",
      "Scraping: https://pratham.org/about/partners/\n",
      "Scraping: https://pratham.org/resources/publications/\n",
      "Scraping: https://pratham.org/daan-utsav-2/\n",
      "Scraping: https://pratham.org/programs/education/vocational-training/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/33.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2024/02/ASER.png (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2024/02/Early-Years.png (invalid extension)\n",
      "Scraping: https://pratham.org/contact/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/12.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/programs/education/elementary/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/16.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/slider/skilling-slider/\n",
      "Scraping: https://pratham.org/programs/pratham-council-for-\n",
      "Scraping: https://pratham.org/wp-content/uploads/2018/12/contact-\n",
      "Scraping: https://pratham.org/2023/11/28/childrens-rights-in-the-asia-pacific-region-critical-reflections-on-participation-education-girls-rights-and-child-marriage/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/20.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/programs/education/early-childhood-education/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/4.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/covid-19-response/prathams-community-based-campaign-\n",
      "Scraping: https://pratham.org/iampratham/\n",
      "Scraping: https://pratham.org/programs/education/digital-initiatives/\n",
      "Scraping: https://pratham.org/wp-content/uploads/2023/07/Pradigi-\n",
      "Error scraping https://pratham.org/wp-content/uploads/2023/07/Pradigi-: 404 Client Error: Not Found for url: https://pratham.org/wp-content/uploads/2023/07/Pradigi-\n",
      "Skipping: https://pratham.org/wp-content/uploads/2021/12/Adobe.png (invalid extension)\n",
      "Scraping: https://pratham.org/programs/education/aser/\n",
      "Scraping: https://www.pratham.org/about/teaching-at-the-right-level/\n",
      "Scraping: https://pratham.org/2024/06/24/dr-rukmini-banerji-was-\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/17.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/slider/second-chance-slider/\n",
      "Scraping: https://pratham.org/get-involved/job-opportunities/\n",
      "Scraping: https://pratham.org/2023/12/12/the-foundational-learning-data-challenge-a-civil-society-view-from-the-global-south/\n",
      "Scraping: https://www.pratham.org/get-involved/donate\n",
      "Error scraping https://www.pratham.org/get-involved/donate: Exceeded 30 redirects.\n",
      "Skipping: https://pratham.org/wp-content/uploads/2024/02/progress-o-meter-04.png (invalid extension)\n",
      "Scraping: https://pratham.org/2023/12/05/rukmini-banerji-co-authors-blog-on-\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/21.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2021/12/Hemant-Goradia.png (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2021/12/Schmidt-Futures.png (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/11.jpg (invalid extension)\n",
      "Scraping: https://instagram.com/prathameducation\n",
      "Scraping: https://pratham.org/\n",
      "Scraping: https://pratham.org/blogs/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2021/12/SMFT.png (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/25.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/32.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/18.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/7.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/30.jpg (invalid extension)\n",
      "Scraping: https://www.facebook.com/PrathamEducationFoundation/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2023/12/Screenshot-2023-12-12-121444-150x150.png (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/22.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/wp-\n",
      "Error scraping https://pratham.org/wp-: 404 Client Error: Not Found for url: https://pratham.org/wp-\n",
      "Skipping: https://pratham.org/wp-content/uploads/2021/12/EAA.png (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/6.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2024/02/PCVC.png (invalid extension)\n",
      "Scraping: https://pratham.org/2023/12/05/rukmini-banerji-co-authors-blog-\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/1.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2021/12/WD.png (invalid extension)\n",
      "Scraping: https://www.youtube.com/user/prathamfoundation\n",
      "Scraping: https://pratham.org/programs/education/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2024/02/Vocational-Training-1.png (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2023/11/whatsapp_image_2023-11-24_at_1.42.51_pm-1-150x150.jpeg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/23.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/2023/12/12/the-foundational-learning-data-\n",
      "Scraping: https://pratham.org/get-involved/internships/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2024/01/ASER-banner.png (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2024/02/Second-Chance.png (invalid extension)\n",
      "Scraping: https://www.pratham.org/about/news/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/10.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/24.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/about/recognition/\n",
      "Scraping: https://pratham.org/2023/11/28/childrens-rights-in-the-\n",
      "Scraping: https://pratham.org/wp-content/uploads/2018/12/get-\n",
      "Scraping: https://pratham.org/wp-content/uploads/2019/05/work-\n",
      "Error scraping https://pratham.org/wp-content/uploads/2019/05/work-: 404 Client Error: Not Found for url: https://pratham.org/wp-content/uploads/2019/05/work-\n",
      "Skipping: https://pratham.org/wp-content/uploads/2018/12/donate-icons.png (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/34.jpg (invalid extension)\n",
      "Scraping: https://www.linkedin.com/company/pratham\n",
      "Scraping: https://pratham.org/about/news/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2024/02/progress-o-meter-03.png (invalid extension)\n",
      "Scraping: https://pratham.org/2023/11/28/childrens-rights-in-the-asia-pacific-\n",
      "Skipping: https://pratham.org/wp-content/uploads/2021/12/Sulzer-Logo.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2021/12/UBS.png (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/9.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/about/annual-reports/\n",
      "Scraping: https://pratham.org/about/legal-financial-information/\n",
      "Scraping: https://pratham.org/about/teaching-at-the-right-level/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/2.jpg (invalid extension)\n",
      "Scraping: https://prathamopenschool.org/\n",
      "Error scraping https://prathamopenschool.org/: HTTPSConnectionPool(host='prathamopenschool.org', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)')))\n",
      "Scraping: https://pratham.org/covid-19-response/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2021/12/Jaideep-Khanna.png (invalid extension)\n",
      "Scraping: https://pratham.org/about/board/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/29.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/about/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/13.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2023/11/RB-landscape-photo-150x150.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/wp-content/uploads/2019/03/pratham-\n",
      "Scraping: https://pratham.org/2023/12/05/rukmini-banerji-co-authors-blog-on-fighting-learning-crisis-with-world-banks-mamta-murthi/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/3.jpg (invalid extension)\n",
      "Skipping: https://prathamorg.blob.core.windows.net/data/Pratham%20during%20Pandemic%20Lessons%20from%20the%20community.pdf (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/28.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2024/02/progress-o-meter-02.png (invalid extension)\n",
      "Scraping: https://pratham.org/slider/aser-2023-beyond-basics/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/8.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/wp-content/uploads/2024/03/education-\n",
      "Error scraping https://pratham.org/wp-content/uploads/2024/03/education-: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Skipping: https://pratham.org/wp-content/uploads/2024/02/progress-o-meter-01.png (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/31.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/about/hamara-gaon/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2021/12/Google.png (invalid extension)\n",
      "Scraping: https://pratham.org/programs/pratham-council-for-vulnerablechildren/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/19.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/2023/12/12/the-foundational-learning-data-challenge-\n",
      "Scraping: https://pratham.org/wp-content/uploads/2018/12/Image-\n",
      "Error scraping https://pratham.org/wp-content/uploads/2018/12/Image-: 404 Client Error: Not Found for url: https://pratham.org/wp-content/uploads/2018/12/Image-\n",
      "Scraping: https://twitter.com/Pratham_India\n",
      "Scraping: https://pratham.org/impact/\n",
      "Scraping: https://pratham.org/2024/06/24/dr-rukmini-banerji-was-conferred-the-doctor-of-letters-honoris-causa-dlitt-by-krea-university/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/15.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/14.jpg (invalid extension)\n",
      "Scraping: https://pratham.org/programs/education/vocational-\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/26.jpg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2024/06/WhatsApp-Image-2024-06-24-at-17.32.47-150x150.jpeg (invalid extension)\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/27.jpg (invalid extension)\n",
      "Scraping: http://www.asercentre.org\n",
      "Scraping: https://pratham.org/slider/ece-slider/\n",
      "Scraping: https://pratham.org/about/leadership/\n",
      "Skipping: https://pratham.org/wp-content/uploads/2020/01/5.jpg (invalid extension)\n",
      "Scraping: http://www.pif.org.in\n",
      "Error scraping http://www.pif.org.in: 403 Client Error: ModSecurity Action for url: http://www.pif.org.in/\n",
      "Scraping successful!\n"
     ]
    }
   ],
   "source": [
    "import html2text\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "def extract_urls_from_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    urls = re.findall(r'https?://[^\\s\\)]+', content)\n",
    "    return list(set(urls))\n",
    "\n",
    "def scrape_page(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def is_valid_url(url):\n",
    "    # List of extensions to ignore\n",
    "    ignore_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.svg', '.pdf', '.zip', '.rar', '.exe', '.mp4', '.mp3']\n",
    "    return not any(url.lower().endswith(ext) for ext in ignore_extensions)\n",
    "\n",
    "def scrape_urls(urls):\n",
    "    scraped_data = {}\n",
    "    \n",
    "    for url in urls:\n",
    "        if is_valid_url(url):\n",
    "            print(f\"Scraping: {url}\")\n",
    "            html_content = scrape_page(url)\n",
    "            if html_content:\n",
    "                key = url.split('/')[-1] if url.split('/')[-1] else url.split('/')[-2]\n",
    "                text_content = html2text.html2text(html_content)\n",
    "                scraped_data[key] = f\"{text_content}\"\n",
    "            time.sleep(1)\n",
    "        else:\n",
    "            print(f\"Skipping: {url} (invalid extension)\")\n",
    "    \n",
    "    return scraped_data\n",
    "\n",
    "def main():\n",
    "    data_folder = 'data'\n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "    \n",
    "    urls = extract_urls_from_file('output.txt')\n",
    "    scraped_data = scrape_urls(urls)\n",
    "    \n",
    "    if scraped_data:\n",
    "        for key, content in scraped_data.items():\n",
    "            with open(os.path.join(data_folder, f'{key}.txt'), 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "        print(\"Scraping successful!\")\n",
    "    else:\n",
    "        print(\"Scraping failed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b3f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to handle .pdf separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "491e6293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fitz\n",
      "  Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.9/site-packages (from fitz) (1.4.2)\n",
      "Collecting configparser\n",
      "  Downloading configparser-7.0.0-py3-none-any.whl (16 kB)\n",
      "Collecting nibabel\n",
      "  Downloading nibabel-5.2.1-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting httplib2\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96 kB 5.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting configobj\n",
      "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.9/site-packages (from fitz) (1.7.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.9/site-packages (from fitz) (1.24.4)\n",
      "Collecting nipype\n",
      "  Downloading nipype-1.8.6-py3-none-any.whl (3.2 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2 MB 15.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyxnat\n",
      "  Downloading pyxnat-1.6.2-py3-none-any.whl (95 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95 kB 4.4 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/anaconda3/lib/python3.9/site-packages (from configobj->fitz) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/anaconda3/lib/python3.9/site-packages (from httplib2->fitz) (3.0.4)\n",
      "Requirement already satisfied: packaging>=17 in /opt/anaconda3/lib/python3.9/site-packages (from nibabel->fitz) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /opt/anaconda3/lib/python3.9/site-packages (from nipype->fitz) (2.8.2)\n",
      "Requirement already satisfied: click>=6.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from nipype->fitz) (8.0.4)\n",
      "Requirement already satisfied: filelock>=3.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from nipype->fitz) (3.13.1)\n",
      "Collecting simplejson>=3.8.0\n",
      "  Downloading simplejson-3.19.2-cp39-cp39-macosx_10_9_x86_64.whl (76 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76 kB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting looseversion\n",
      "  Downloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting rdflib>=5.0.0\n",
      "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 531 kB 18 kB/s eta 0:00:0101\n",
      "\u001b[?25hCollecting traits!=5.0,<6.4,>=4.6\n",
      "  Downloading traits-6.3.2-cp39-cp39-macosx_10_9_x86_64.whl (5.0 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.0 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydot>=1.2.3\n",
      "  Downloading pydot-3.0.1-py3-none-any.whl (22 kB)\n",
      "Collecting prov>=1.5.2\n",
      "  Downloading prov-2.0.1-py3-none-any.whl (421 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 421 kB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /opt/anaconda3/lib/python3.9/site-packages (from nipype->fitz) (2.7.1)\n",
      "Collecting etelemetry>=0.2.0\n",
      "  Downloading etelemetry-0.3.1-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (from etelemetry>=0.2.0->nipype->fitz) (2.27.1)\n",
      "Collecting ci-info>=0.2\n",
      "  Downloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: lxml>=3.3.5 in /opt/anaconda3/lib/python3.9/site-packages (from prov>=1.5.2->nipype->fitz) (4.8.0)\n",
      "Collecting rdflib>=5.0.0\n",
      "  Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 528 kB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 41 kB 2.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.22.4-cp39-cp39-macosx_10_15_x86_64.whl (17.7 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.7 MB 493 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.9/site-packages (from pandas->fitz) (2021.3)\n",
      "Collecting pathlib>=1.0\n",
      "  Downloading pathlib-1.0.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->etelemetry>=0.2.0->nipype->fitz) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests->etelemetry>=0.2.0->nipype->fitz) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests->etelemetry>=0.2.0->nipype->fitz) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests->etelemetry>=0.2.0->nipype->fitz) (2021.10.8)\n",
      "Installing collected packages: pyparsing, isodate, rdflib, numpy, ci-info, traits, simplejson, pydot, prov, pathlib, nibabel, looseversion, etelemetry, pyxnat, nipype, httplib2, configparser, configobj, fitz\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.4\n",
      "    Uninstalling pyparsing-3.0.4:\n",
      "      Successfully uninstalled pyparsing-3.0.4\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.22.4 which is incompatible.\u001b[0m\n",
      "Successfully installed ci-info-0.3.0 configobj-5.0.8 configparser-7.0.0 etelemetry-0.3.1 fitz-0.0.1.dev2 httplib2-0.22.0 isodate-0.6.1 looseversion-1.3.0 nibabel-5.2.1 nipype-1.8.6 numpy-1.22.4 pathlib-1.0.1 prov-2.0.1 pydot-3.0.1 pyparsing-3.1.2 pyxnat-1.6.2 rdflib-6.3.2 simplejson-3.19.2 traits-6.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ecffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting frontend\n",
      "  Downloading frontend-0.0.3-py3-none-any.whl (32 kB)\n",
      "Collecting starlette>=0.12.0\n",
      "  Downloading starlette-0.38.2-py3-none-any.whl (72 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting uvicorn>=0.7.1\n",
      "  Downloading uvicorn-0.30.4-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62 kB 6.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: itsdangerous>=1.1.0 in /opt/anaconda3/lib/python3.9/site-packages (from frontend) (2.0.1)\n",
      "Collecting aiofiles\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/anaconda3/lib/python3.9/site-packages (from starlette>=0.12.0->frontend) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /opt/anaconda3/lib/python3.9/site-packages (from starlette>=0.12.0->frontend) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.9/site-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (1.2.0)\n",
      "Requirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.9/site-packages (from uvicorn>=0.7.1->frontend) (8.0.4)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58 kB 8.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: h11, uvicorn, starlette, aiofiles, frontend\n",
      "Successfully installed aiofiles-24.1.0 frontend-0.0.3 h11-0.14.0 starlette-0.38.2 uvicorn-0.30.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7375798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (2.27.1)\n",
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.24.9-cp39-none-macosx_10_9_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests) (1.26.9)\n",
      "Collecting PyMuPDFb==1.24.9\n",
      "  Downloading PyMuPDFb-1.24.9-py3-none-macosx_10_9_x86_64.whl (15.3 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.3 MB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
      "Successfully installed PyMuPDF-1.24.9 PyMuPDFb-1.24.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d1d1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://prathamorg.blob.core.windows.net/data/Pratham%20during%20Pandemic%20Lessons%20from%20the%20community.pdf to data/Pratham%20during%20Pandemic%20Lessons%20from%20the%20community.pdf\n",
      "Converted data/Pratham%20during%20Pandemic%20Lessons%20from%20the%20community.pdf to data/Pratham%20during%20Pandemic%20Lessons%20from%20the%20community.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_pdf_urls_from_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    pdf_urls = re.findall(r'https?://[^\\s\\)]+\\.pdf', content)\n",
    "    return list(set(pdf_urls))\n",
    "\n",
    "def download_pdf(url, save_path):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded {url} to {save_path}\")\n",
    "        return save_path\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_pdf_to_text(pdf_path, txt_path):\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        with open(txt_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(text)\n",
    "        print(f\"Converted {pdf_path} to {txt_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {pdf_path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    data_folder = 'data'\n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "    \n",
    "    pdf_urls = extract_pdf_urls_from_file('output.txt')\n",
    "    \n",
    "    for url in pdf_urls:\n",
    "        pdf_filename = os.path.join(data_folder, os.path.basename(url))\n",
    "        txt_filename = pdf_filename.replace('.pdf', '.txt')\n",
    "        \n",
    "        downloaded_pdf = download_pdf(url, pdf_filename)\n",
    "        if downloaded_pdf:\n",
    "            convert_pdf_to_text(downloaded_pdf, txt_filename)\n",
    "            os.remove(downloaded_pdf)  # Optionally, remove the downloaded PDF file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
